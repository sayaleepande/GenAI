{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayaleepande/GenAI/blob/main/M8_Lab1_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![RAG Intro Lab](https://www.dropbox.com/scl/fi/hyyhk4rkslkgi6rd1ki5z/RAG_Intro_Lab.png?rlkey=31iuzmmvt9ta3xf649jma4y67&raw=1)\n"
      ],
      "metadata": {
        "id": "F8wzOI-QD1d9"
      },
      "id": "F8wzOI-QD1d9"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e0f1adbd",
      "metadata": {
        "id": "e0f1adbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50459641-ae67-4e0d-851e-fe80d283e411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“¦ Installing Required Libraries for LangChain RAG Lab (Quiet Mode)\n",
        "# ==================================================\n",
        "\n",
        "# --- Core LangChain and OpenAI Integration ---\n",
        "!pip install -q --upgrade langchain langchain-community langchain-openai\n",
        "\n",
        "# --- OpenAI SDK ---\n",
        "# 'openai': Required to access GPT-3.5/4 and manage API keys, works with both LangChain and direct calls\n",
        "!pip install -q --upgrade openai\n",
        "\n",
        "# --- Vector Databases for Retrieval (RAG) ---\n",
        "# 'faiss-cpu': Facebook's FAISS for fast vector search (in-memory or persistent)\n",
        "# 'chromadb': Lightweight vector database, ideal for local demos and quick setup\n",
        "!pip install -q --upgrade faiss-cpu chromadb\n",
        "\n",
        "# --- Tokenization and Unstructured Data Support ---\n",
        "# 'tiktoken': Fast, efficient tokenizer (used with OpenAI, supports counting tokens accurately)\n",
        "# 'unstructured': Loads/cleans data from PDFs, DOCX, HTML, email, etc. for use in retrieval pipelines\n",
        "# 'unstructured[pdf]': Adds PDF parsing support (using pdfminer, pypdf, etc.)\n",
        "# 'pypdf', 'pdfminer.six': Popular PDF parsing backends, required for some document loaders\n",
        "!pip install -q --upgrade tiktoken unstructured \"unstructured[pdf]\" pypdf pdfminer.six\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9f6983d2",
      "metadata": {
        "id": "9f6983d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d3c409b-40d7-4fa6-8c2d-6dcb4767111d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All libraries imported and categorized successfully!\n"
          ]
        }
      ],
      "source": [
        "# ğŸ“š LangChain RAG Lab: Library Imports & Setup\n",
        "# ====================================================\n",
        "# âœ… This cell handles all required imports, grouped by category for clarity.\n",
        "\n",
        "# ğŸ§± System & Environment Setup\n",
        "import os  # Environment variable access\n",
        "import requests  # For fetching remote resources (e.g., PDFs, data files)\n",
        "from google.colab import userdata  # Accessing Colab-specific secure data\n",
        "\n",
        "# ğŸ§ª Jupyter & Colab Display Utilities\n",
        "import ipywidgets as widgets  # Interactive widgets\n",
        "from IPython.display import clear_output, display, HTML  # Display controls\n",
        "\n",
        "# ğŸ”‘ OpenAI API\n",
        "import openai  # Optional: raw API access (not required for LangChain unless custom use)\n",
        "\n",
        "# ğŸ§  LangChain Core Modules\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  # LLM + Embeddings via OpenAI\n",
        "from langchain_core.prompts import PromptTemplate  # Structured prompt templates\n",
        "from langchain.memory import ConversationBufferMemory  # For chat history memory\n",
        "\n",
        "\n",
        "# âœ… Confirmation\n",
        "print(\"âœ… All libraries imported and categorized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".description-box {\n",
        "    background-color: #f8f9fa;\n",
        "    padding: 14px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #e0e0e0;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        ".code-note {\n",
        "    background-color: #fff;\n",
        "    padding: 10px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #dadce0;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ–¨ï¸ Pretty Print Function</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"description-box\">\n",
        "    <p style=\"margin: 0 0 8px 0;\">The <span class=\"highlight\">pretty_print()</span> function enhances output readability by transforming standard text into styled HTML blocks. This utility function replaces basic print statements with visually appealing formatted displays that improve the user experience when viewing model responses and system outputs.</p>\n",
        "    \n",
        "    <p style=\"margin: 8px 0 0 0;\">Key features include automatic detection and formatting of bulleted lists, proper line break handling, and consistent visual styling that matches the laboratory's design theme. The function accepts two parameters: the text content to display and an optional title that appears as a header above the formatted output.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"code-note\">\n",
        "    <strong>Usage:</strong> Replace standard <code>print()</code> statements with <code>pretty_print()</code> throughout your notebook to maintain consistent, professional output formatting.\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "5wu-5wP8z3h8"
      },
      "id": "5wu-5wP8z3h8"
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ–¨ï¸ pretty_print(): Reusable HTML display function for model outputs\n",
        "def pretty_print(text, title=\"ğŸ¤– Model Response\"):\n",
        "    \"\"\"\n",
        "    Display model response in styled HTML block.\n",
        "    Handles bulleted lists and line breaks.\n",
        "    \"\"\"\n",
        "    lines = text.strip().split('\\n')\n",
        "    is_bulleted = all(line.strip().startswith((\"-\", \"â€¢\", \"*\")) for line in lines if line.strip())\n",
        "\n",
        "    if is_bulleted:\n",
        "        list_items = ''.join(f\"<li>{line.lstrip('-â€¢* ').strip()}</li>\" for line in lines if line.strip())\n",
        "        content_html = f\"<ul style='margin-top: 6px;'>{list_items}</ul>\"\n",
        "    else:\n",
        "        content_html = text.replace(\"\\n\", \"<br>\")  # fallback for plain lines\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
        "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
        "                color:#202124; line-height:1.6;\">\n",
        "      <strong>{title}</strong><br><br>\n",
        "      {content_html}\n",
        "    </div>\n",
        "    \"\"\"))"
      ],
      "metadata": {
        "id": "gJZi1HGbz-XD"
      },
      "id": "gJZi1HGbz-XD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ”‘ OpenAI API Key Setup from Colab Secrets</h2>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "gGqlpWgd0LKn"
      },
      "id": "gGqlpWgd0LKn"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2d4e47a7",
      "metadata": {
        "id": "2d4e47a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "49b52a3f-af61-4cdc-c66c-433a3eeab98e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>âœ… API Key Setup</strong><br><br>\n",
              "      ğŸ” OpenAI API Key successfully set from Colab Secrets!\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ==================================================\n",
        "# ğŸ”‘ OpenAI API Key Setup from Colab Secrets\n",
        "# ==================================================\n",
        "\n",
        "# âœ… Retrieve OpenAI API Key securely from Colab's secret storage\n",
        "try:\n",
        "    from google.colab import userdata  # Colab-specific secure storage\n",
        "    openai_key = userdata.get('OPENAI_API_KEY')  # Must be pre-stored via UI\n",
        "\n",
        "    if openai_key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "        pretty_print(\"ğŸ” OpenAI API Key successfully set from Colab Secrets!\", title=\"âœ… API Key Setup\")\n",
        "    else:\n",
        "        pretty_print(\"âš ï¸ OpenAI API Key not found in Colab Secrets. Please add it via Colab â¤ More â¤ Secrets.\", title=\"âŒ Missing API Key\")\n",
        "\n",
        "except Exception as e:\n",
        "    pretty_print(f\"ğŸš« Error retrieving OpenAI API Key: {e}\", title=\"â— API Key Setup Error\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ”· Part 1: Non-RAG Model Implementation</h2>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "O-6iyAWy1t02"
      },
      "id": "O-6iyAWy1t02"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# SIMPLE LANGCHAIN LLM QUERY - NO RAG COMPONENTS\n",
        "# Direct language model query using LangChain without document retrieval\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "# Execute query\n",
        "query = \"What do I learn in the GenAI course in 3 bullets, software, application. Also who is the prof? any hints for me to gain a good grade?\"\n",
        "response = llm.invoke(query)\n",
        "\n",
        "# Display result\n",
        "pretty_print(response.content, title=\"ğŸ¯ Direct LLM Response\")"
      ],
      "metadata": {
        "id": "jAN-AfeL_cvQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "fa081d5b-3809-48d3-9494-b0d974d57612"
      },
      "id": "jAN-AfeL_cvQ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ¯ Direct LLM Response</strong><br><br>\n",
              "      <ul style='margin-top: 6px;'><li>In the GenAI course, you will learn about genetic algorithms, artificial neural networks, and evolutionary computing, which are all techniques used in artificial intelligence.</li><li>You will also learn how to apply these techniques to solve various real-world problems in fields such as optimization, machine learning, and robotics.</li><li>The professor for the course is Dr. Sophia Lee, an expert in artificial intelligence and genetic algorithms. To gain a good grade in the course, make sure to actively participate in lectures, complete all assignments on time, and seek help from the professor or teaching assistants when needed. Additionally, it is important to stay updated on the latest developments in the field of artificial intelligence and apply your knowledge to practical projects.</li></ul>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".explanation-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 16px;\n",
        "    margin: 16px 0;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "\n",
        ".process-diagram {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    border-radius: 8px;\n",
        "    padding: 20px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".step-container {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(4, 1fr);\n",
        "    gap: 15px;\n",
        "    margin: 20px 0;\n",
        "}\n",
        "\n",
        ".step-card {\n",
        "    background: #f8f9fa;\n",
        "    border-radius: 8px;\n",
        "    padding: 15px;\n",
        "    text-align: center;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "    position: relative;\n",
        "}\n",
        "\n",
        ".step-number {\n",
        "    background: #1a73e8;\n",
        "    color: white;\n",
        "    width: 28px;\n",
        "    height: 28px;\n",
        "    border-radius: 50%;\n",
        "    display: flex;\n",
        "    align-items: center;\n",
        "    justify-content: center;\n",
        "    font-weight: bold;\n",
        "    margin: 0 auto 10px;\n",
        "}\n",
        "\n",
        ".step-arrow {\n",
        "    position: absolute;\n",
        "    right: -10px;\n",
        "    top: 50%;\n",
        "    transform: translateY(-50%);\n",
        "    color: #1a73e8;\n",
        "    font-size: 20px;\n",
        "}\n",
        "\n",
        ".technology-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 12px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".tech-card {\n",
        "    background: white;\n",
        "    border: 1px solid #e0e0e0;\n",
        "    border-radius: 6px;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ”· Part 2: RAG Model Implementation</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"explanation-box\">\n",
        "    <h3>Understanding the RAG Architecture</h3>\n",
        "    <p>The Retrieval-Augmented Generation system enhances language model responses by incorporating document-specific context. Unlike standard LLMs that rely solely on training data, RAG systems actively search through your documents to find relevant information before generating responses.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"chart-container\">\n",
        "    <img src=\"https://www.dropbox.com/scl/fi/w7w1hfzgzdu46ydv9on00/RAG_Structure.png?rlkey=ef8r6nfdtbg3zvw90900w6rt8&dl=1\" alt=\"RAG Architecture Overview\" style=\"width: 70%; max-width: 70%;\">\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "_PRn2D8jvdfc"
      },
      "id": "_PRn2D8jvdfc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div class=\"explanation-box\" style=\"background-color: #f8f9fa;\">\n",
        "    <h3>How Retrieval Works</h3>\n",
        "    <p>When a user submits a query, the system:</p>\n",
        "    <ol style=\"margin: 8px 0 0 20px; padding: 0;\">\n",
        "        <li>Converts the query into an embedding vector using the same model</li>\n",
        "        <li>Searches the FAISS index for the k most similar document chunks</li>\n",
        "        <li>Passes these relevant chunks as context to the language model</li>\n",
        "        <li>Generates a response grounded in the retrieved information</li>\n",
        "    </ol>\n",
        "    <p style=\"margin-top: 12px;\">This approach ensures responses are based on your specific documents rather than general knowledge, significantly improving accuracy and relevance.</p>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "D0wL3XSYGSQg"
      },
      "id": "D0wL3XSYGSQg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px 14px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".task-details {\n",
        "    background-color: #f8f9fa;\n",
        "    padding: 12px;\n",
        "    margin: 8px 0;\n",
        "    border-radius: 4px;\n",
        "    border: 1px solid #e0e0e0;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".process-list {\n",
        "    margin: 8px 0 0 0;\n",
        "    padding-left: 20px;\n",
        "}\n",
        "\n",
        ".process-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #444;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"task-header\">\n",
        "    <h3>ğŸ“¥ Task 1: Document Loading</h3>\n",
        "    <div class=\"task-details\">\n",
        "        <p style=\"margin: 0 0 8px 0;\">This task retrieves the course syllabus PDF from Dropbox and prepares it for RAG processing. The document undergoes three key transformations to enable efficient semantic search:</p>\n",
        "        <ul class=\"process-list\">\n",
        "            <li><span class=\"highlight\">Download:</span> Fetch the PDF file using the provided Dropbox URL</li>\n",
        "            <li><span class=\"highlight\">Load:</span> Extract text content from all pages using PyPDFLoader</li>\n",
        "            <li><span class=\"highlight\">Chunk:</span> Split the document into 1000-character segments with 200-character overlap to preserve context boundaries</li>\n",
        "        </ul>\n",
        "        <p style=\"margin: 8px 0 0 0;\">The chunking strategy ensures that related information remains together while creating appropriately sized segments for embedding generation. The overlap prevents important context from being lost at chunk boundaries.</p>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "WbwXKoqixNYb"
      },
      "id": "WbwXKoqixNYb"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> DOCUMENT LOADING AND PROCESSING\n",
        "# This cell downloads the PDF from Dropbox, loads it into memory,\n",
        "# and splits it into manageable chunks for vector search\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# ğŸ“¦ Document Loaders\n",
        "from langchain.document_loaders import PyPDFLoader  # Load content from PDFs\n",
        "from langchain_community.document_loaders import TextLoader  # Load plain text files\n",
        "\n",
        "# âœ‚ï¸ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Import the text splitter here\n",
        "\n",
        "\n",
        "# Download PDF from Dropbox\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fi/zedqrdppb6et1sm3s09r6/IE_5250_Applied_Generative_AI-2025.pdf?rlkey=tn3130kcd5o03twalmydn8t6p&e=1&dl=1\"\n",
        "pdf_path = \"/content/document.pdf\"\n",
        "\n",
        "response = requests.get(dropbox_url)\n",
        "with open(pdf_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Load and process the PDF\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split into chunks for better retrieval accuracy\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "pretty_print(f\"PDF successfully downloaded and processed\\n{len(documents)} pages converted into {len(docs)} searchable chunks\",\n",
        "             title=\"ğŸ“¥ Document Loading Complete\")"
      ],
      "metadata": {
        "id": "TE5LmmBV2nfv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "64af379d-4c29-44db-9061-75f107ed84c8"
      },
      "id": "TE5LmmBV2nfv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ“¥ Document Loading Complete</strong><br><br>\n",
              "      PDF successfully downloaded and processed<br>5 pages converted into 16 searchable chunks\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 10px 12px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<!-- Task 2 Header -->\n",
        "<div class=\"task-header\">\n",
        "    <h3>ğŸ§® Task 2: Embedding Generation & Vector Store Creation</h3>\n",
        "</div>\n",
        "\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "xdxwNlK7yZcF"
      },
      "id": "xdxwNlK7yZcF"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> EMBEDDING GENERATION AND VECTOR STORE CREATION\n",
        "# This cell converts text chunks into vector embeddings using OpenAI's\n",
        "# model and stores them in a FAISS index for fast similarity search\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# âœ‚ï¸ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Split text into chunks\n",
        "\n",
        "# ğŸ“š Vector Store & Embeddings\n",
        "from langchain.vectorstores import FAISS  # FAISS for fast vector search\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Create FAISS vector store\n",
        "vector_db = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "# Prepare sample chunks display\n",
        "sample_chunks = []\n",
        "for i in range(min(3, len(docs))):\n",
        "    chunk_preview = docs[i].page_content[:150].strip()\n",
        "    sample_chunks.append(f\"â€¢ Chunk {i+1}: {chunk_preview}...\")\n",
        "\n",
        "sample_text = f\"Embeddings successfully created for {len(docs)} chunks\\n\\nSample chunks:\\n\" + \"\\n\".join(sample_chunks)\n",
        "pretty_print(sample_text, title=\"ğŸ§  Embedding Generation Complete\")\n"
      ],
      "metadata": {
        "id": "va7gBXMBxSUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "89720367-1820-435e-a05a-a5aa9e396faa"
      },
      "id": "va7gBXMBxSUJ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ§  Embedding Generation Complete</strong><br><br>\n",
              "      Embeddings successfully created for 16 chunks<br><br>Sample chunks:<br>â€¢ Chunk 1: IE 5250: Applied Generative AI<br>Prof. Mohammad Dehghani<br>\"Prioritize utilizing readily available tools and frameworks instead of developing AI applicati...<br>â€¢ Chunk 2: Course Overview<br>Examines how Generative AI (GenAI) and autonomous Agentic AI systems leverage<br>large language models (LLMs) to extract insights, genera...<br>â€¢ Chunk 3: tical implementation of GenAI.<br>Note: There are no prerequisites for this course, although familiarity with cod-<br>ing in Python is a plus.<br>Course Object...\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".task-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 10px 12px;\n",
        "    margin: 10px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.05em;\n",
        "    margin: 0;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "\n",
        "<!-- Task 3 Header -->\n",
        "<div class=\"task-header\">\n",
        "    <h3>ğŸ” Task 3: Query and Retrieval</h3>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "nEKNYkMDyesF"
      },
      "id": "nEKNYkMDyesF"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> RETRIEVAL AND QUESTION ANSWERING\n",
        "# This cell sets up the RAG chain, performs retrieval testing,\n",
        "# and executes queries against the document\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# ğŸ” Retrieval-Augmented Generation (RAG)\n",
        "from langchain.chains import RetrievalQA  # Combine retriever + LLM into a QA system\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Create retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Test retrieval functionality\n",
        "test_docs = retriever.get_relevant_documents(\"document\")\n",
        "retrieval_status = f\"Retrieval system operational: {len(test_docs)} documents successfully retrieved\"\n",
        "\n",
        "# Build RAG chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Execute query\n",
        "query = \"What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?\"\n",
        "result = rag_chain({\"query\": query})\n",
        "\n",
        "# Format the complete response\n",
        "query_result_text = f\"{retrieval_status}\\n\\nQuery: {query}\\n\\nAnswer:\\n{result['result']}\\n\\nSource Documents Used: {len(result['source_documents'])}\"\n",
        "pretty_print(query_result_text, title=\"ğŸ” RAG Query Results\")"
      ],
      "metadata": {
        "id": "Aa0-P4bq8ehZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "fb52d3af-fdba-4401-f6ad-91d1a1e08dd1"
      },
      "id": "Aa0-P4bq8ehZ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-16664b1977f5>:17: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  test_docs = retriever.get_relevant_documents(\"document\")\n",
            "<ipython-input-8-16664b1977f5>:30: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = rag_chain({\"query\": query})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ” RAG Query Results</strong><br><br>\n",
              "      Retrieval system operational: 4 documents successfully retrieved<br><br>Query: What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?<br><br>Answer:<br>In the GenAI course (IE 5250: Applied Generative AI) taught by Prof. Mohammad Dehghani, you will learn:<br><br>1. How to apply GenAI for data analytics in real-world scenarios like exploring the relationship between presidential elections and Bitcoin prices.<br>2. Using GenAI to predict demand and optimize decisions in scenarios like the Beer Game simulation for supply chain management.<br>3. Developing decision-making models, health transition models, and addressing engineering problems through AI-enabled optimization using GenAI.<br><br>To gain a good grade in the course, prioritize utilizing the essential tools and platforms mentioned in the course outline, actively participate in class activities, complete projects and hackathons effectively in teams, and ensure you have a good understanding of Python basics for programming tasks.<br><br>Source Documents Used: 4\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #f0f6ff; border-left: 3px solid #1a73e8; padding: 16px; margin: 12px 0; border-radius: 4px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; color: #1a1a1a; font-size: 14px; line-height: 1.4; max-width: 750px;\">\n",
        "\n",
        "<h2 style=\"color: #1a73e8; font-size: 1.15em; font-weight: 600; margin: 0 0 12px 0;\">ğŸ”· Vector Database Alternatives to FAISS</h2>\n",
        "\n",
        "<p>While FAISS excels at similarity search, several alternatives offer unique features for RAG applications. Each database addresses different needs regarding ease of use, scalability, and deployment options.</p>\n",
        "\n",
        "<ul style=\"margin: 12px 0; padding-left: 20px;\">\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://www.trychroma.com/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">ChromaDB</a> â€“ Open-source embedding DB with simple API design and LangChain support.  \n",
        "    <a href=\"https://docs.trychroma.com/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more â†’</a>\n",
        "  </li>\n",
        "  \n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://www.pinecone.io/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Pinecone</a> â€“ Fully managed vector DB, ideal for production-scale with zero infra hassle.  \n",
        "    <a href=\"https://docs.pinecone.io/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more â†’</a>\n",
        "  </li>\n",
        "\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://weaviate.io/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Weaviate</a> â€“ Combines vector + structured search with GraphQL and ML modules.  \n",
        "    <a href=\"https://weaviate.io/developers/weaviate\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more â†’</a>\n",
        "  </li>\n",
        "\n",
        "  <li style=\"margin: 10px 0;\">\n",
        "    <a href=\"https://qdrant.tech/\" target=\"_blank\" style=\"color: #1a73e8; font-weight: 600; text-decoration: none;\">Qdrant</a> â€“ Rust-based engine offering fast vector search and advanced filtering.  \n",
        "    <a href=\"https://qdrant.tech/documentation/\" target=\"_blank\" style=\"color: #1a73e8; text-decoration: none;\">Learn more â†’</a>\n",
        "  </li>\n",
        "</ul>\n",
        "\n",
        "<div style=\"margin-top: 14px; padding-top: 12px; border-top: 1px solid #dadce0; font-size: 0.9em; color: #555;\">\n",
        "  <strong>Selection Guide:</strong> Use <b>ChromaDB</b> for quick dev, <b>Pinecone</b> for managed infra, <b>Weaviate</b> for hybrid search, or <b>Qdrant</b> for speed.  \n",
        "  <i>FAISS</i> is still great for offline and lightweight use.\n",
        "</div>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "i6sGnvE9AH3_"
      },
      "id": "i6sGnvE9AH3_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ“Š Loading CSV Data in LangChain</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">LangChain's <span class=\"highlight\">CSVLoader</span> enables seamless integration of structured tabular data into RAG systems. This capability transforms spreadsheet data into searchable documents, allowing natural language queries against datasets containing sales records, inventory, research data, or any information organized in rows and columns.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: white; border: 1px solid #dadce0; padding: 20px; border-radius: 6px; margin: 16px 0;\">\n",
        "    <h3 style=\"color: #1a73e8; font-size: 1em; margin: 0 0 10px 0;\">ğŸ“Š CSV Data Loading</h3>\n",
        "    <p style=\"margin: 0 0 8px 0; font-size: 0.9em;\">Process structured tabular data for analysis and question-answering. The CSVLoader converts each row into a document, preserving column relationships while enabling semantic search across your datasets. This approach bridges the gap between traditional data analysis and natural language processing.</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 0.85em; color: #666;\"><strong>Common use cases:</strong> Sales and financial data, product catalogs, customer records, survey responses, scientific datasets, inventory management, performance metrics</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 12px; margin: 16px 0; border-radius: 4px; border: 1px solid #e0e0e0;\">\n",
        "    <p style=\"margin: 0; font-size: 0.9em;\"><strong>ğŸ’¡ Pro Tip:</strong> CSV data maintains its structured nature even after conversion to documents. This allows RAG systems to answer complex questions about trends, comparisons, and aggregations within your tabular data.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "7TSID1pEPdQV"
      },
      "id": "7TSID1pEPdQV"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# This cell generates a non-grounded LLM response without using any data source\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "# âœ… Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# âœ… Query about GDP\n",
        "query = (\n",
        "    \"Compare the GDP of USA, Japan, China, and Qatar in 1980 and 2020. \"\n",
        "    \"For each country, show GDP in 1980, GDP in 2020, and percent change in a concise format, e.g., \"\n",
        "    \"<flag emoji> Country: (1980 â†’ GDP), (2020 â†’ GDP), (% change: #.##%). \"\n",
        "    \"Use billions or trillions of USD, rounded.\"\n",
        ")\n",
        "hallucinated_response = llm.invoke(query).content\n",
        "\n",
        "# âœ… Format and display\n",
        "hallucination_output = f\"\"\"\n",
        "ğŸ§  Hallucinated Response (No RAG):\n",
        "---------------------------------\n",
        "{hallucinated_response}\n",
        "\"\"\"\n",
        "\n",
        "pretty_print(hallucination_output, title=\"ğŸŒ GDP Query without RAG\")\n"
      ],
      "metadata": {
        "id": "XmeE91hiWrUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "1b97c033-6cfd-401c-8329-9639e7026f75"
      },
      "id": "XmeE91hiWrUf",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸŒ GDP Query without RAG</strong><br><br>\n",
              "      <br>ğŸ§  Hallucinated Response (No RAG):<br>---------------------------------<br>ğŸ‡ºğŸ‡¸ USA: ($2.86 trillion â†’ $21.43 trillion), (% change: 648.95%)<br>ğŸ‡¯ğŸ‡µ Japan: ($1.09 trillion â†’ $5.08 trillion), (% change: 365.14%)<br>ğŸ‡¨ğŸ‡³ China: ($0.31 trillion â†’ $14.34 trillion), (% change: 4538.71%)<br>ğŸ‡¶ğŸ‡¦ Qatar: ($4.17 billion â†’ $146.6 billion), (% change: 3405.75%)<br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6VZH8mO8J7ck"
      },
      "id": "6VZH8mO8J7ck"
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "#>> RAG RESPONSE (CSV) â€“ GPT-4, One-Line Query, No Prompt Template\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# âœ… Step 1: Download CSV from Dropbox\n",
        "csv_url = \"https://www.dropbox.com/scl/fi/nzc5p2gpgb3wja2kf7qdz/GDP_World_Bank.csv?rlkey=jydgntc8jfkm6ajyswovmso3z&st=gwqgc976&dl=1\"\n",
        "with open(\"gdp_data.csv\", \"wb\") as f:\n",
        "    f.write(requests.get(csv_url).content)\n",
        "\n",
        "# âœ… Step 2: Load CSV\n",
        "try:\n",
        "    loader = CSVLoader(\n",
        "        file_path=\"gdp_data.csv\",\n",
        "        encoding=\"utf-8\",\n",
        "        csv_args={\n",
        "            'delimiter': ',',\n",
        "            'quotechar': '\"',\n",
        "            'fieldnames': None\n",
        "        }\n",
        "    )\n",
        "    docs = loader.load()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "    df = pd.read_csv(\"gdp_data.csv\")\n",
        "    from langchain.schema import Document\n",
        "    docs = []\n",
        "    for idx, row in df.iterrows():\n",
        "        content = f\"Country: {row.get('Country Name', 'Unknown')}, \"\n",
        "        for col in df.columns:\n",
        "            if col not in ['Country Name', 'Country Code']:\n",
        "                content += f\"{col}: {row.get(col, 'N/A')}, \"\n",
        "        docs.append(Document(page_content=content, metadata={\"row\": idx}))\n",
        "\n",
        "# âœ… Step 3: Optional - Split documents\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# âœ… Step 4: Embedding and vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "vector_db = FAISS.from_documents(split_docs if split_docs else docs, embedding)\n",
        "\n",
        "# âœ… Step 5: Retriever setup\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": 10,\n",
        "        \"score_threshold\": 0.5\n",
        "    }\n",
        ")\n",
        "\n",
        "# âœ… Step 6: RAG chain with no template\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# âœ… Step 7: Simple one-line query\n",
        "# âœ… Query about GDP\n",
        "query = (\n",
        "    \"Compare the GDP of China, Japan, China, and Qatar in 1980 and 2020. \"\n",
        "    \"For each country, show GDP in 1980, GDP in 2020, and percent change in a concise format, e.g., \"\n",
        "    \"<flag emoji> Country: (1980 â†’ GDP), (2020 â†’ GDP), (% change: #.##%). \"\n",
        "    \"Use billions or trillions of USD, rounded.\"\n",
        ")\n",
        "\n",
        "\n",
        "rag_response = rag_chain.invoke({\"query\": query})\n",
        "\n",
        "# âœ… Step 8: Display result\n",
        "rag_output = f\"\"\"\n",
        "Retrieval Status: {len(split_docs if 'split_docs' in locals() else docs)} documents in vector store\n",
        "\n",
        "ğŸ“Š RAG-Based Response (Using CSV):\n",
        "---------------------------------\n",
        "{rag_response['result']}\n",
        "\n",
        "Source Documents Used: {len(rag_response['source_documents'])}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "pretty_print(rag_output, title=\"ğŸŒ GDP Query with CSV-RAG (Simple Query)\")\n"
      ],
      "metadata": {
        "id": "cgIHcYRiY4Rl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "b3bca231-2e57-4a22-8d8a-8bb8871ff394"
      },
      "id": "cgIHcYRiY4Rl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-95c3239bb7a2>:48: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedding = OpenAIEmbeddings()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸŒ GDP Query with CSV-RAG (Simple Query)</strong><br><br>\n",
              "      <br>Retrieval Status: 266 documents in vector store<br><br>ğŸ“Š RAG-Based Response (Using CSV):<br>---------------------------------<br>ğŸ‡¨ğŸ‡³ China: (1980 â†’ $1.91 trillion), (2020 â†’ $14.7 trillion), (% change: 669.63%)<br>ğŸ‡¯ğŸ‡µ Japan: (1980 â†’ $1.13 trillion), (2020 â†’ $5.06 trillion), (% change: 347.79%)<br>ğŸ‡¨ğŸ‡³ China: (1980 â†’ $1.91 trillion), (2020 â†’ $14.7 trillion), (% change: 669.63%)<br>ğŸ‡¶ğŸ‡¦ Qatar: (1980 â†’ $7.83 billion), (2020 â†’ $144 billion), (% change: 1738.44%)<br><br>Source Documents Used: 10<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        ".data-type-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 16px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".data-card {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".code-example {\n",
        "    background-color: #f5f5f5;\n",
        "    border: 1px solid #ddd;\n",
        "    border-radius: 4px;\n",
        "    padding: 12px;\n",
        "    margin: 10px 0;\n",
        "    font-family: 'Courier New', monospace;\n",
        "    font-size: 0.85em;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".use-case-list {\n",
        "    margin: 8px 0;\n",
        "    padding-left: 20px;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".use-case-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #555;\n",
        "}\n",
        "\n",
        ".chart-container {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    margin: 16px 0;\n",
        "    text-align: center;\n",
        "}\n",
        "\n",
        ".chart-container img {\n",
        "    max-width: 70%;\n",
        "    height: auto;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "\n",
        ".question-box {\n",
        "    background-color: #fff3cd;\n",
        "    border-left: 3px solid #ffc107;\n",
        "    padding: 12px;\n",
        "    margin: 16px 0;\n",
        "    border-radius: 4px;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ“Š World Bank GDP Data Analysis</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">The provided data from the <span class=\"highlight\">World Bank</span> shows the GDP of countries as shown in the image below. This dataset provides valuable insights into global economic indicators and can be used to test the accuracy of <span class=\"highlight\">RAG model implementations</span> when processing economic data.</p>\n",
        "</div>\n",
        "\n",
        "<div class=\"chart-container\">\n",
        "    <img src=\"https://www.dropbox.com/scl/fi/bmitdcpfoqmib886t26vv/GDP_Chart.png?rlkey=1xmwtmvybl7h1rp3dxvbj972m&raw=1\" alt=\"GDP Chart\" style=\"width: 70%; max-width: 70%;\">\n",
        "</div>\n",
        "\n",
        "<div class=\"question-box\">\n",
        "    <h3 style=\"color: #856404; margin: 0;\">â“ Did your RAG model provide accurate values based on this dataset?</h3>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "VX0mSQR6knhP"
      },
      "id": "VX0mSQR6knhP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "\n",
        ".data-type-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: repeat(2, 1fr);\n",
        "    gap: 16px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".data-card {\n",
        "    background: white;\n",
        "    border: 1px solid #dadce0;\n",
        "    padding: 16px;\n",
        "    border-radius: 6px;\n",
        "    border-top: 3px solid #1a73e8;\n",
        "}\n",
        "\n",
        ".code-example {\n",
        "    background-color: #f5f5f5;\n",
        "    border: 1px solid #ddd;\n",
        "    border-radius: 4px;\n",
        "    padding: 12px;\n",
        "    margin: 10px 0;\n",
        "    font-family: 'Courier New', monospace;\n",
        "    font-size: 0.85em;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "h3 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1em;\n",
        "    margin: 0 0 8px 0;\n",
        "}\n",
        "\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "\n",
        ".use-case-list {\n",
        "    margin: 8px 0;\n",
        "    padding-left: 20px;\n",
        "    font-size: 0.9em;\n",
        "}\n",
        "\n",
        ".use-case-list li {\n",
        "    margin: 4px 0;\n",
        "    color: #555;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>ğŸ”· Loading External Data: HTML & CSV in LangChain</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0;\">LangChain extends beyond PDF processing to support diverse data sources. <span class=\"highlight\">HTML loaders</span> enable web content ingestion for real-time information retrieval, while <span class=\"highlight\">CSV loaders</span> handle structured data analysis. These capabilities allow RAG systems to work with dynamic web content and tabular datasets alongside traditional documents.</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background: white; border: 1px solid #dadce0; padding: 20px; border-radius: 6px; margin: 16px 0;\">\n",
        "    <h3 style=\"color: #1a73e8; font-size: 1em; margin: 0 0 10px 0;\">ğŸŒ HTML Data Loading</h3>\n",
        "    <p style=\"margin: 0 0 8px 0; font-size: 0.9em;\">Extract content from web pages for up-to-date information retrieval. Perfect for incorporating current events, documentation, or any web-based content into your RAG system. LangChain's HTML loaders enable seamless integration of web content into your document processing pipeline.</p>\n",
        "    <p style=\"margin: 8px 0 0 0; font-size: 0.85em; color: #666;\"><strong>Common use cases:</strong> News articles and blog posts, technical documentation, Wikipedia entries, company websites, product pages, FAQ sections</p>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; padding: 12px; margin: 16px 0; border-radius: 4px; border: 1px solid #e0e0e0;\">\n",
        "    <p style=\"margin: 0; font-size: 0.9em;\"><strong>ğŸ’¡ Pro Tip:</strong> Both loaders convert content into LangChain Document objects, maintaining consistency across different data sources. This allows you to apply the same embedding and retrieval pipeline regardless of whether your source is a PDF, web page, or CSV file.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "cTX-PTnGAtwj"
      },
      "id": "cTX-PTnGAtwj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ‹**Hands-On: RAG with HTML Data**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒ Load HTML from a Webpage or Local File\n",
        "\n",
        "```python\n",
        "from langchain.document_loaders import HTMLLoader\n",
        "\n",
        "# Load from a webpage\n",
        "html_loader = HTMLLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n",
        "html_docs = html_loader.load()\n",
        "\n",
        "# OR load from a local file\n",
        "# html_loader = HTMLLoader(\"data/my_page.html\")\n",
        "# html_docs = html_loader.load()\n"
      ],
      "metadata": {
        "id": "jS5bBlCKjE4H"
      },
      "id": "jS5bBlCKjE4H"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFEJo0VsgkSu",
        "outputId": "b6ece970-8aeb-4924-f18c-8ca944322934"
      },
      "id": "VFEJo0VsgkSu",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.64)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uslMI2CPgsmQ",
        "outputId": "d6df1c57-47c7-4e78-ca20-144192183a24"
      },
      "id": "uslMI2CPgsmQ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.64)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade langchain  # Core framework for LLMs\n",
        "!pip install -q --upgrade langchain-community"
      ],
      "metadata": {
        "id": "E4z9bMUcgQv0"
      },
      "id": "E4z9bMUcgQv0",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# âœ‹ **Hands-On: Load & Retrieve Renewable Energy Info from Wikipedia**\n",
        "# ==================================================\n",
        "# ğŸ“Œ **Task Instructions:**\n",
        "# 1ï¸âƒ£ Fill in the missing placeholders (`-----`) to complete the process.\n",
        "# 2ï¸âƒ£ Use `HTMLLoader` to load Wikipedia data.\n",
        "# 3ï¸âƒ£ Split text into retrievable chunks.\n",
        "# 4ï¸âƒ£ Convert chunks into vector embeddings using FAISS.\n",
        "# 5ï¸âƒ£ Use retrieval to answer a question about renewable energy.\n",
        "\n",
        "#from langchain.document_loaders import HTMLLoader\n",
        "#from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "import requests\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 1: Load Wikipedia Page on Renewable Energy\n",
        "# ==================================================\n",
        "wiki_url = \"https://en.wikipedia.org/wiki/Renewable_energy\"\n",
        "\n",
        "html_path = \"renewable_energy.html\"\n",
        "\n",
        "response = requests.get(wiki_url)\n",
        "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "loader = UnstructuredHTMLLoader(html_path)  # Load HTML from Wikipedia\n",
        "documents = loader.load()  # Extract text from the page\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 2: Split Text into Chunks\n",
        "# ==================================================\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)   # Split extracted text into smaller chunks\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 3: Convert Chunks to Embeddings & Store in FAISS\n",
        "# ==================================================\n",
        "embedding_model = OpenAIEmbeddings()  # Use OpenAIEmbeddings or another model\n",
        "vector_db = FAISS.from_documents(docs if docs else documents, embedding_model)  # Convert docs into vector embeddings and store in FAISS\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 4: Create a Retriever to Fetch Relevant Information\n",
        "# ==================================================\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": 10,\n",
        "        \"score_threshold\": 0.5\n",
        "    }\n",
        ")  # Convert FAISS vector store into a retriever\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 5: Ask AI a Question About Renewable Energy\n",
        "# ==================================================\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)  # Define the RAG pipeline\n",
        "\n",
        "query = \"What are the main types of renewable energy sources?\"\n",
        "response_rag = rag_chain.run(query)\n",
        "\n",
        "# âœ… Step 6: Display Retrieved Answer\n",
        "print(\"\\nğŸŒ ğŸ”‹ AI Answer on Renewable Energy:\")\n",
        "print(response_rag)\n"
      ],
      "metadata": {
        "id": "wMfwf0xUz1Zq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95836a7-8ebb-43fd-a939-c481851ab157"
      },
      "id": "wMfwf0xUz1Zq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-190be2167a04>:67: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response_rag = rag_chain.run(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸŒ ğŸ”‹ AI Answer on Renewable Energy:\n",
            "The main types of renewable energy sources are solar power, wind power, hydroelectricity, geothermal energy, and biomass. Some also consider nuclear power a renewable power source, although this is controversial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<style>\n",
        "body {\n",
        "    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
        "    line-height: 1.4;\n",
        "    color: #1a1a1a;\n",
        "    max-width: 750px;\n",
        "    margin: 0 auto;\n",
        "    padding: 8px;\n",
        "    font-size: 14px;\n",
        "}\n",
        ".section-header {\n",
        "    background-color: #e8f0fe;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "}\n",
        ".intro-box {\n",
        "    background-color: #f0f6ff;\n",
        "    border-left: 3px solid #1a73e8;\n",
        "    padding: 12px;\n",
        "    margin: 12px 0;\n",
        "    border-radius: 4px;\n",
        "    font-size: 0.95em;\n",
        "}\n",
        "h1 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.5em;\n",
        "    text-align: center;\n",
        "    margin: 20px 0;\n",
        "}\n",
        "h2 {\n",
        "    color: #1a73e8;\n",
        "    font-size: 1.15em;\n",
        "    margin: 0;\n",
        "}\n",
        ".highlight {\n",
        "    color: #1a73e8;\n",
        "    font-weight: 600;\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<h1>ğŸ‰ Congratulations!</h1>\n",
        "\n",
        "<div class=\"section-header\">\n",
        "    <h2>âœ… Lab Completed: RAG with LangChain & FAISS</h2>\n",
        "</div>\n",
        "\n",
        "<div class=\"intro-box\">\n",
        "    <p style=\"margin: 0 0 12px 0;\">You successfully integrated <span class=\"highlight\">LangChain</span> with <span class=\"highlight\">FAISS</span> to build a RAG pipeline for World Bank GDP data. Great job mastering vector databases and semantic search!</p>\n",
        "    <p style=\"margin: 0;\">â“ You need to extend this lab based on other embeddings or/and vector settings. Check Canvas and lab requirements for more details.</p>\n",
        "</div>\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "id": "IAK9Pn5U6_6c"
      },
      "id": "IAK9Pn5U6_6c"
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG model implementation with the same PDF file as above but, using ChromaDB\n",
        "\n",
        "# Task 1 - Document Loading: Document Loading implementation as above\n",
        "from langchain.document_loaders import PyPDFLoader  # Load content from PDFs\n",
        "from langchain_community.document_loaders import TextLoader  # Load plain text files\n",
        "\n",
        "# âœ‚ï¸ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter # Import the text splitter here\n",
        "\n",
        "\n",
        "# Download PDF from Dropbox\n",
        "dropbox_url = \"https://www.dropbox.com/scl/fi/zedqrdppb6et1sm3s09r6/IE_5250_Applied_Generative_AI-2025.pdf?rlkey=tn3130kcd5o03twalmydn8t6p&e=1&dl=1\"\n",
        "pdf_path = \"/content/document.pdf\"\n",
        "\n",
        "response = requests.get(dropbox_url)\n",
        "with open(pdf_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Load and process the PDF\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split into chunks for better retrieval accuracy\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "pretty_print(f\"PDF successfully downloaded and processed\\n{len(documents)} pages converted into {len(docs)} searchable chunks\",\n",
        "             title=\"ğŸ“¥ Document Loading Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "6S7znldmvVQF",
        "outputId": "a7486374-0fc9-4462-fe95-fd02a03d33f7"
      },
      "id": "6S7znldmvVQF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ“¥ Document Loading Complete</strong><br><br>\n",
              "      PDF successfully downloaded and processed<br>5 pages converted into 16 searchable chunks\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below is Task 2 - Embedding Generation & Vector Store Creation: using a ChromaDB\n",
        "\n",
        "# âœ‚ï¸ Text Processing & Chunking\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Split text into chunks\n",
        "\n",
        "# ğŸ“š Vector Store & Embeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Create Chroma vector store\n",
        "vector_db = Chroma.from_documents(docs, embedding_model, persist_directory=\"chroma_db\")\n",
        "\n",
        "# Prepare sample chunks display\n",
        "sample_chunks = []\n",
        "for i in range(min(3, len(docs))):\n",
        "    chunk_preview = docs[i].page_content[:150].strip()\n",
        "    sample_chunks.append(f\"â€¢ Chunk {i+1}: {chunk_preview}...\")\n",
        "\n",
        "sample_text = f\"Embeddings successfully created for {len(docs)} chunks\\n\\nSample chunks:\\n\" + \"\\n\".join(sample_chunks)\n",
        "pretty_print(sample_text, title=\"ğŸ§  Embedding Generation Complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "b6a5TSnwvgXP",
        "outputId": "b2b89320-0a6f-4505-b6b5-42117da83b45"
      },
      "id": "b6a5TSnwvgXP",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ§  Embedding Generation Complete</strong><br><br>\n",
              "      Embeddings successfully created for 16 chunks<br><br>Sample chunks:<br>â€¢ Chunk 1: IE 5250: Applied Generative AI<br>Prof. Mohammad Dehghani<br>\"Prioritize utilizing readily available tools and frameworks instead of developing AI applicati...<br>â€¢ Chunk 2: Course Overview<br>Examines how Generative AI (GenAI) and autonomous Agentic AI systems leverage<br>large language models (LLMs) to extract insights, genera...<br>â€¢ Chunk 3: tical implementation of GenAI.<br>Note: There are no prerequisites for this course, although familiarity with cod-<br>ing in Python is a plus.<br>Course Object...\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3 - Query & Retieval\n",
        "\n",
        "# ğŸ” Retrieval-Augmented Generation (RAG)\n",
        "from langchain.chains import RetrievalQA  # Combine retriever + LLM into a QA system\n",
        "\n",
        "# Initialize language model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Create retriever\n",
        "retriever = vector_db.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Test retrieval functionality\n",
        "test_docs = retriever.get_relevant_documents(\"document\")\n",
        "retrieval_status = f\"Retrieval system operational: {len(test_docs)} documents successfully retrieved\"\n",
        "\n",
        "# Build RAG chain\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Execute query\n",
        "query = \"What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?\"\n",
        "result = rag_chain({\"query\": query})\n",
        "\n",
        "# Format the complete response\n",
        "query_result_text = f\"{retrieval_status}\\n\\nQuery: {query}\\n\\nAnswer:\\n{result['result']}\\n\\nSource Documents Used: {len(result['source_documents'])}\"\n",
        "pretty_print(query_result_text, title=\"ğŸ” RAG Query Results\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "q5SSVlt9yO2g",
        "outputId": "953dce7e-ceb7-4be9-b433-fa01459a068e"
      },
      "id": "q5SSVlt9yO2g",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸ” RAG Query Results</strong><br><br>\n",
              "      Retrieval system operational: 4 documents successfully retrieved<br><br>Query: What do I learn in the GenAI course in 3 bullets, software, appliciaon. Also who is the prof? any hitns for me to gain a good grade?<br><br>Answer:<br>In the GenAI course (IE 5250: Applied Generative AI) taught by Prof. Mohammad Dehghani, you will learn:<br><br>1. How to apply GenAI for data analytics in real-world scenarios like exploring the relationship between presidential elections and Bitcoin prices.<br>2. How to use GenAI to predict demand and optimize decisions in scenarios like the Beer Game simulation for supply chain management.<br>3. How to develop decision-making models and leverage GenAI for health transitions modeling and addressing engineering problems like scheduling and resource planning.<br><br>For software requirements, you will need familiarity with Python basics and access to COE Virtual Lab (VLab) for required software packages. Additionally, you will need to set up your own OpenAI API key for case studies using OpenAI's API.<br><br>To gain a good grade, prioritize utilizing the tools and frameworks provided in the course instead of developing AI applications from scratch. Active participation in class activities, completing projects in teams, and engaging in hackathons will also contribute to your grade. Remember to check your running grade on CANVAS to stay updated on your progress.<br><br>Source Documents Used: 4\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With CSV-RAG using ChromaDB\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# âœ… Step 1: Download CSV from Dropbox\n",
        "csv_url = \"https://www.dropbox.com/scl/fi/nzc5p2gpgb3wja2kf7qdz/GDP_World_Bank.csv?rlkey=jydgntc8jfkm6ajyswovmso3z&st=gwqgc976&dl=1\"\n",
        "with open(\"gdp_data.csv\", \"wb\") as f:\n",
        "    f.write(requests.get(csv_url).content)\n",
        "\n",
        "# âœ… Step 2: Load CSV\n",
        "try:\n",
        "    loader = CSVLoader(\n",
        "        file_path=\"gdp_data.csv\",\n",
        "        encoding=\"utf-8\",\n",
        "        csv_args={\n",
        "            'delimiter': ',',\n",
        "            'quotechar': '\"',\n",
        "            'fieldnames': None\n",
        "        }\n",
        "    )\n",
        "    docs = loader.load()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "    df = pd.read_csv(\"gdp_data.csv\")\n",
        "    from langchain.schema import Document\n",
        "    docs = []\n",
        "    for idx, row in df.iterrows():\n",
        "        content = f\"Country: {row.get('Country Name', 'Unknown')}, \"\n",
        "        for col in df.columns:\n",
        "            if col not in ['Country Name', 'Country Code']:\n",
        "                content += f\"{col}: {row.get(col, 'N/A')}, \"\n",
        "        docs.append(Document(page_content=content, metadata={\"row\": idx}))\n",
        "\n",
        "# âœ… Step 3: Optional - Split documents\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "# âœ… Step 4: Embedding and vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "vector_db = Chroma.from_documents(split_docs if split_docs else docs, embedding)\n",
        "\n",
        "# âœ… Step 5: Retriever setup\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": 10,\n",
        "  #      \"score_threshold\": 0.5\n",
        "    }\n",
        ")\n",
        "\n",
        "# âœ… Step 6: RAG chain with no template\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "rag_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# âœ… Step 7: Simple one-line query\n",
        "# âœ… Query about GDP\n",
        "query = (\n",
        "    \"Compare the GDP of China, Japan, China, and Qatar in 1980 and 2020. \"\n",
        "    \"For each country, show GDP in 1980, GDP in 2020, and percent change in a concise format, e.g., \"\n",
        "    \"<flag emoji> Country: (1980 â†’ GDP), (2020 â†’ GDP), (% change: #.##%). \"\n",
        "    \"Use billions or trillions of USD, rounded.\"\n",
        ")\n",
        "\n",
        "\n",
        "rag_response = rag_chain.invoke({\"query\": query})\n",
        "\n",
        "# âœ… Step 8: Display result\n",
        "rag_output = f\"\"\"\n",
        "Retrieval Status: {len(split_docs if 'split_docs' in locals() else docs)} documents in vector store\n",
        "\n",
        "ğŸ“Š RAG-Based Response (Using CSV):\n",
        "---------------------------------\n",
        "{rag_response['result']}\n",
        "\n",
        "Source Documents Used: {len(rag_response['source_documents'])}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "pretty_print(rag_output, title=\"ğŸŒ GDP Query with CSV-RAG (Simple Query)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "r6jvn9ZGzoXr",
        "outputId": "28833163-1093-4ac2-a68e-849befbbde22"
      },
      "id": "r6jvn9ZGzoXr",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"background-color:#f8f9fc; border-left:5px solid #4285f4;\n",
              "                padding:16px; margin-top:16px; font-family:'Segoe UI', sans-serif;\n",
              "                color:#202124; line-height:1.6;\">\n",
              "      <strong>ğŸŒ GDP Query with CSV-RAG (Simple Query)</strong><br><br>\n",
              "      <br>Retrieval Status: 266 documents in vector store<br><br>ğŸ“Š RAG-Based Response (Using CSV):<br>---------------------------------<br>ğŸ‡¨ğŸ‡³ China: (1980 â†’ $191 billion), (2020 â†’ $14.7 trillion), (% change: 7596.34%)<br>ğŸ‡¯ğŸ‡µ Japan: (1980 â†’ $1.13 trillion), (2020 â†’ $5.06 trillion), (% change: 347.79%)<br>ğŸ‡¨ğŸ‡³ China: (1980 â†’ $191 billion), (2020 â†’ $14.7 trillion), (% change: 7596.34%)<br>ğŸ‡¶ğŸ‡¦ Qatar: (1980 â†’ $7.83 billion), (2020 â†’ $144 billion), (% change: 1738.44%)<br><br>Source Documents Used: 10<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG with HTML data using ChromaDB\n",
        "\n",
        "import requests\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "wiki_url = \"https://en.wikipedia.org/wiki/Renewable_energy\"\n",
        "\n",
        "html_path = \"renewable_energy.html\"\n",
        "\n",
        "response = requests.get(wiki_url)\n",
        "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "loader = UnstructuredHTMLLoader(html_path)  # Load HTML from Wikipedia\n",
        "documents = loader.load()  # Extract text from the page\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 2: Split Text into Chunks\n",
        "# ==================================================\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)   # Split extracted text into smaller chunks\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 3: Convert Chunks to Embeddings & Store in FAISS\n",
        "# ==================================================\n",
        "embedding_model = OpenAIEmbeddings()  # Use OpenAIEmbeddings or another model\n",
        "vector_db = Chroma.from_documents(docs if docs else documents, embedding_model)  # Convert docs into vector embeddings and store in FAISS\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 4: Create a Retriever to Fetch Relevant Information\n",
        "# ==================================================\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\n",
        "        \"k\": 10,\n",
        "#        \"score_threshold\": 0.5\n",
        "    }\n",
        ")\n",
        "\n",
        "# ==================================================\n",
        "# âœ… Step 5: Ask AI a Question About Renewable Energy\n",
        "# ==================================================\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)  # Define the RAG pipeline\n",
        "\n",
        "query = \"What are the main types of renewable energy sources?\"\n",
        "response_rag = rag_chain.run(query)\n",
        "\n",
        "# âœ… Step 6: Display Retrieved Answer\n",
        "print(\"\\nğŸŒ ğŸ”‹ AI Answer on Renewable Energy:\")\n",
        "print(response_rag)\n"
      ],
      "metadata": {
        "id": "24DqhjXBPAvI",
        "outputId": "4313cee2-389b-44ce-ae5b-d7f16997284b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "24DqhjXBPAvI",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸŒ ğŸ”‹ AI Answer on Renewable Energy:\n",
            "The main types of renewable energy sources are solar power, wind power, hydroelectricity, geothermal energy, and biomass.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}